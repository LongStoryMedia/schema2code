import os
import sys
from typing import Any, Dict, Optional, List, Set, Tuple
from ..util.resolver import SchemaRefResolver
from ..util.writer import Writer
from ..util.schema_helpers import (
    to_pascal_case,
    enum_member_name,
    enum_member_desc,
    process_definitions_and_nested_types,
)


class ProtoGenerator:
    @staticmethod
    def generate(
        schema: Dict[str, Any],
        package_name: str = "schema",
        schema_file: Optional[str] = None,
        ref_resolver: Optional[SchemaRefResolver] = None,
        is_main: bool = True,
        referenced_by: Optional[str] = None,
        go_package: Optional[str] = None,
        external_imports: Optional[List[str]] = None,
    ) -> str:
        """Generate Protocol Buffer message definitions from a JSON schema"""
        # Initialize ref resolver if needed
        if ref_resolver is None and schema_file is not None:
            ref_resolver = SchemaRefResolver(schema_file, schema)

        # Track already processed types to avoid duplicates
        processed_types = set()  # Initialize output
        output = []

        # Add auto-generation comment
        output.append("// GENERATED CODE - DO NOT EDIT")
        output.append("// Generated by schema2code proto generator")
        output.append("")

        # Add proto syntax version
        output.append('syntax = "proto3";')
        output.append("")

        # Add package declaration
        output.append(f"package {package_name};")
        output.append("")

        # Add go_package option if provided
        if go_package:
            # Make sure go_package has a proper import path with at least one dot or slash
            if "." not in go_package and "/" not in go_package:
                go_package = f"github.com/example/{go_package}"
            output.append(f'option go_package = "{go_package}";')
            output.append("")

        # Add imports
        imports = ProtoGenerator._get_required_imports(schema, ref_resolver)

        # Add any external imports provided
        if external_imports:
            imports.extend(external_imports)

        # Add imports for referenced types - check properties and references
        if schema.get("properties"):
            for _, prop_schema in schema.get("properties", {}).items():
                # Check direct references
                if "$ref" in prop_schema and ref_resolver:
                    ref = prop_schema["$ref"]
                    if not ref.startswith("#"):  # External reference
                        ref_parts = ref.split("/")
                        file_name = ref_parts[-1]
                        # Handle YAML and JSON extensions
                        if file_name.endswith((".yaml", ".yml", ".json")):
                            base_name = file_name.rsplit(".", 1)[0]
                            proto_import = f"{base_name}.proto"
                            imports.append(proto_import)

                # Check array item references
                if prop_schema.get("type") == "array" and prop_schema.get(
                    "items", {}
                ).get("$ref"):
                    item_ref = prop_schema.get("items", {}).get("$ref")
                    if not item_ref.startswith("#"):  # External reference
                        ref_parts = item_ref.split("/")
                        file_name = ref_parts[-1]
                        # Handle YAML and JSON extensions
                        if file_name.endswith((".yaml", ".yml", ".json")):
                            base_name = file_name.rsplit(".", 1)[0]
                            proto_import = f"{base_name}.proto"
                            imports.append(proto_import)
                    elif item_ref.startswith(
                        "#/definitions/"
                    ):  # Internal reference to definition
                        # Check if this definition is itself a reference to an external file
                        definition_name = item_ref.split("/")[-1]
                        if definition_name in schema.get("definitions", {}):
                            def_schema = schema["definitions"][definition_name]
                            if isinstance(def_schema, dict) and "$ref" in def_schema:
                                def_ref = def_schema["$ref"]
                                if not def_ref.startswith("#"):
                                    # This is an external reference through a definition
                                    ref_file = def_ref.split("/")[-1]
                                    if ref_file.endswith((".yaml", ".yml", ".json")):
                                        base_name = ref_file.rsplit(".", 1)[0]
                                        proto_import = f"{base_name}.proto"
                                        imports.append(proto_import)

        # Remove duplicates and sort
        imports = sorted(set(imports))

        for import_path in imports:
            # Keep the import paths simple without relative paths
            # protoc will resolve them based on the proto_path argument
            output.append(f'import "{import_path}";')

        if imports:
            output.append("")  # Process and generate root type
        title = schema.get("title")
        root_type_name = title if title else "Root"
        root_type_name = to_pascal_case(root_type_name)

        # Handle root enum type
        if "enum" in schema:
            output.extend(ProtoGenerator._generate_enum_type(schema, root_type_name))
        # Handle root object type
        elif "type" in schema and schema["type"] == "object":
            # Generate the root message
            output.extend(
                ProtoGenerator._generate_message_type(
                    schema, root_type_name, processed_types, ref_resolver
                )
            )

        # Process definitions
        if "definitions" in schema:
            for def_name, def_schema in schema.get("definitions", {}).items():
                type_name = to_pascal_case(def_name)

                # Skip if we've already processed this type
                if type_name in processed_types:
                    continue

                # Generate the message definition
                if def_schema.get("type") == "object":
                    output.extend(
                        ProtoGenerator._generate_message_type(
                            def_schema, type_name, processed_types, ref_resolver
                        )
                    )
                elif "enum" in def_schema:
                    output.extend(
                        ProtoGenerator._generate_enum_type(def_schema, type_name)
                    )

        # Join all lines
        return "\n".join(output)

    @staticmethod
    def _get_required_imports(
        schema: Dict[str, Any], ref_resolver: Optional[SchemaRefResolver] = None
    ) -> List[str]:
        """Determine which imports are needed based on the schema types"""
        imports = set()

        # Check for timestamps and other special formats
        for _, prop_schema in schema.get("properties", {}).items():
            if prop_schema.get("format") == "date-time":
                imports.add("google/protobuf/timestamp.proto")
            elif prop_schema.get("format") == "date":
                imports.add("google/protobuf/timestamp.proto")
            elif prop_schema.get("format") == "time":
                imports.add("google/protobuf/timestamp.proto")
            elif prop_schema.get("format") == "duration":
                imports.add("google/protobuf/duration.proto")
            elif prop_schema.get("format") == "any":
                imports.add("google/protobuf/any.proto")

            # Check for refs that might need imports
            if "$ref" in prop_schema and ref_resolver:
                ref_path = prop_schema["$ref"]

                # External references (direct imports)
                if not ref_path.startswith("#"):
                    # Extract the referenced file name (removing extension)
                    ref_file = ref_path.split("/")[-1]

                    # If it's a .proto file, add it as import
                    if ref_file.endswith(".proto"):
                        imports.add(ref_file)
                    # For other file types, we'll convert to proto name
                    elif ref_file.endswith((".yaml", ".yml", ".json")):
                        base_name = ref_file.rsplit(".", 1)[0]
                        proto_file = f"{base_name}.proto"
                        imports.add(proto_file)
                # Internal references to definitions that might point to external files
                elif ref_path.startswith("#/definitions/"):
                    # Check if this definition is itself a reference to an external file
                    definition_name = ref_path.split("/")[-1]
                    if definition_name in schema.get("definitions", {}):
                        def_schema = schema["definitions"][definition_name]
                        if isinstance(def_schema, dict) and "$ref" in def_schema:
                            def_ref = def_schema["$ref"]
                            if not def_ref.startswith("#"):
                                # This is an external reference through a definition
                                ref_file = def_ref.split("/")[-1]
                                if ref_file.endswith((".yaml", ".yml", ".json")):
                                    base_name = ref_file.rsplit(".", 1)[0]
                                    proto_file = f"{base_name}.proto"
                                    imports.add(proto_file)

        # Check for well-known wrapper types
        for _, prop_schema in schema.get("properties", {}).items():
            if prop_schema.get("format") in [
                "google.protobuf.StringValue",
                "google.protobuf.BoolValue",
                "google.protobuf.Int32Value",
                "google.protobuf.Int64Value",
                "google.protobuf.UInt32Value",
                "google.protobuf.UInt64Value",
                "google.protobuf.FloatValue",
                "google.protobuf.DoubleValue",
            ]:
                imports.add("google/protobuf/wrappers.proto")
                break

        return sorted(list(imports))

    @staticmethod
    def _generate_message_type(
        schema: Dict[str, Any],
        type_name: str,
        processed_types: Set[str],
        ref_resolver: Optional[SchemaRefResolver] = None,
    ) -> List[str]:
        """Generate a protocol buffer message type from a schema object"""
        # Add this type to processed types to avoid duplicates
        processed_types.add(type_name)

        output = []

        # Add documentation comment if available
        description = schema.get("description", "").strip()
        if description:
            output.append(f"// {description}")

        # Start message definition
        output.append(f"message {type_name} {{")

        # Process properties
        field_number = 1
        properties = schema.get("properties", {})
        required_props = set(schema.get("required", []))

        for prop_name, prop_schema in properties.items():
            # Get field type
            field_type, is_repeated, nested_type = ProtoGenerator._get_field_type(
                prop_schema, ref_resolver, processed_types, prop_name
            )

            # Generate nested types if needed
            if nested_type:
                output.extend([f"  {line}" for line in nested_type])
                output.append("")

            # Add documentation comment for the field if available
            prop_desc = prop_schema.get("description", "").strip()
            if prop_desc:
                output.append(f"  // {prop_desc}")

            # Determine if the field is required
            is_required = prop_name in required_props
            proto_label = "repeated " if is_repeated else ""

            # Add the field definition
            snake_name = ProtoGenerator._to_snake_case(prop_name)
            output.append(f"  {proto_label}{field_type} {snake_name} = {field_number};")
            field_number += 1  # Check if we need to handle additional properties
        if schema.get("additionalProperties"):
            # If additionalProperties is true or an object, add a map field
            if schema.get("additionalProperties") is True:
                # Generic string-to-string map for true
                output.append(f"  // Additional properties as key-value pairs")
                output.append(
                    f"  map<string, string> additional_properties = {field_number};"
                )
                field_number += 1
            elif isinstance(schema.get("additionalProperties"), dict):
                add_props = schema.get("additionalProperties", {})

                # If additionalProperties is an empty object, use string value
                if not add_props:
                    output.append(f"  // Additional properties as key-value pairs")
                    output.append(
                        f"  map<string, string> additional_properties = {field_number};"
                    )
                    field_number += 1
                else:
                    value_type, _, nested_type = ProtoGenerator._get_field_type(
                        add_props, ref_resolver, processed_types, "value"
                    )

                    if nested_type:
                        output.extend([f"  {line}" for line in nested_type])
                        output.append("")

                    output.append(f"  // Additional properties as key-value pairs")
                    output.append(
                        f"  map<string, {value_type}> additional_properties = {field_number};"
                    )
                    field_number += 1
        # Close message definition
        output.append("}")
        output.append("")

        return output

    @staticmethod
    def _generate_enum_type(schema: Dict[str, Any], type_name: str) -> List[str]:
        """Generate a protocol buffer enum type from a schema enum"""
        output = []

        # Add documentation comment if available
        description = schema.get("description", "").strip()
        if description:
            output.append(f"// {description}")

        # Start enum definition
        output.append(f"enum {type_name} {{")

        # Proto3 requires first enum value to be zero
        output.append(f"  {type_name.upper()}_UNSPECIFIED = 0;")

        # Process enum values
        enum_values = schema.get("enum", [])
        enum_names = schema.get("enumNames", [])
        enum_descriptions = schema.get("enumDescriptions", [])

        for i, value in enumerate(enum_values):
            # Get enum member name
            member_name = enum_member_name(enum_names, value, i, title=type_name)
            member_name = member_name.upper()
            member_name = ProtoGenerator._sanitize_enum_name(member_name)

            # Add description if available
            member_desc = enum_member_desc(enum_descriptions, value, i)
            if member_desc:
                output.append(f"  // {member_desc}")

            # Add enum value (use index + 1 since we already used 0 for UNSPECIFIED)
            output.append(f"  {member_name} = {i + 1};")

        # Close enum definition
        output.append("}")
        output.append("")

        return output

    @staticmethod
    def _get_field_type(
        schema: Dict[str, Any],
        ref_resolver: Optional[SchemaRefResolver],
        processed_types: Set[str],
        prop_name: str,
    ) -> Tuple[str, bool, Optional[List[str]]]:
        """Determine the protocol buffer type for a schema property"""
        nested_type = None
        is_repeated = False

        # Handle oneOf, anyOf, allOf, not blocks
        if "oneOf" in schema:
            # For oneOf in Protocol Buffers, create a oneof group in the parent message
            # This is handled at the caller level, but we need to provide a default type
            # For now, we'll just use the first option as default
            if schema["oneOf"]:
                return ProtoGenerator._get_field_type(
                    schema["oneOf"][0], ref_resolver, processed_types, prop_name
                )
            return "google.protobuf.Any", is_repeated, None

        if "anyOf" in schema:
            # Similar to oneOf, but semantic difference is not representable in protobuf
            if schema["anyOf"]:
                return ProtoGenerator._get_field_type(
                    schema["anyOf"][0], ref_resolver, processed_types, prop_name
                )
            return "google.protobuf.Any", is_repeated, None

        if "allOf" in schema:
            # For allOf, take the most specific type (usually last)
            if schema["allOf"]:
                return ProtoGenerator._get_field_type(
                    schema["allOf"][-1], ref_resolver, processed_types, prop_name
                )
            return "google.protobuf.Any", is_repeated, None

        if "not" in schema:
            # "not" doesn't have a direct representation in Protocol Buffers
            return "google.protobuf.Any", is_repeated, None

        # Handle $ref
        if "$ref" in schema and ref_resolver:
            ref = schema["$ref"]
            referred_schema = ref_resolver.resolve_ref(ref)

            # Check if this is an external reference
            if not ref.startswith("#"):
                # Extract the filename without extension to use as import
                ref_parts = ref.split("/")
                file_name = ref_parts[-1]

                # Handle YAML and JSON extensions
                if (
                    file_name.endswith(".yaml")
                    or file_name.endswith(".yml")
                    or file_name.endswith(".json")
                ):
                    base_name = file_name.rsplit(".", 1)[0]

                    # For common schema patterns, use the title from the referred schema if available
                    if referred_schema and "title" in referred_schema:
                        type_name = to_pascal_case(referred_schema["title"])
                    else:
                        type_name = to_pascal_case(base_name)
                else:
                    # If no extension, use as is
                    type_name = to_pascal_case(file_name)

                # For schema references that might be enums, check the referred schema
                if referred_schema:
                    if "enum" in referred_schema:
                        # For external enum reference, use the type directly
                        # We're assuming the enum has already been or will be generated
                        # as a separate file with the same name as the referenced file
                        if referred_schema.get("type") == "string":
                            # This is a standalone enum
                            return type_name, is_repeated, nested_type
                        else:
                            # Generate inline enum if it's an embedded enum type
                            enum_name = to_pascal_case(prop_name) + "Enum"
                            nested_type = ProtoGenerator._generate_enum_type(
                                referred_schema, enum_name
                            )
                            return enum_name, is_repeated, nested_type

                # For external references, use the type name
                return type_name, is_repeated, nested_type
            else:
                # Extract type name from ref for internal references
                ref_parts = ref.split("/")
                type_name = to_pascal_case(ref_parts[-1])
                return type_name, is_repeated, nested_type

        # Handle array type
        if schema.get("type") == "array":
            is_repeated = True
            items_schema = schema.get("items", {})

            # Handle nested arrays (arrays of arrays)
            if items_schema.get("type") == "array":
                # Create a new message type for the inner array
                inner_array_name = to_pascal_case(prop_name) + "List"
                inner_items_schema = items_schema.get("items", {})
                inner_item_type, _, inner_nested_type = ProtoGenerator._get_field_type(
                    inner_items_schema, ref_resolver, processed_types, "Value"
                )

                # Create a nested message for the inner array
                nested_type = []
                nested_type.append(f"message {inner_array_name} {{")
                nested_type.append(f"  repeated {inner_item_type} values = 1;")
                nested_type.append("}")
                nested_type.append("")

                # Return the inner array message type with is_repeated=True
                return inner_array_name, is_repeated, nested_type
            else:
                # Handle simple arrays (non-nested)
                item_type, _, item_nested_type = ProtoGenerator._get_field_type(
                    items_schema, ref_resolver, processed_types, prop_name + "Item"
                )
                return item_type, is_repeated, item_nested_type

        # Handle enum type
        if "enum" in schema:
            # Use property name as type name with Enum suffix if not already ending with "Enum"
            base_name = to_pascal_case(prop_name)
            type_name = base_name if base_name.endswith("Enum") else base_name + "Enum"
            nested_type = ProtoGenerator._generate_enum_type(schema, type_name)
            return type_name, is_repeated, nested_type

        # Handle object type (nested message)
        if schema.get("type") == "object":
            type_name = to_pascal_case(prop_name)

            # Check if the object has properties
            has_properties = bool(schema.get("properties", {}))

            if type_name not in processed_types:
                # Generate the nested message type
                nested_type = []

                # Add description if available
                if schema.get("description"):
                    nested_type.append(f"// {schema['description']}")

                # Start message definition
                nested_type.append(f"message {type_name} {{")

                # If the object has properties, generate them
                if has_properties:
                    # Process all properties
                    props_output = ProtoGenerator._generate_message_type(
                        schema, type_name, processed_types, ref_resolver
                    )
                    # Remove first and last lines (message name and closing bracket) as we're generating those here
                    if len(props_output) > 2:
                        props_output = props_output[1:-2]
                        nested_type.extend(props_output)
                else:
                    # Add a reserved field to avoid empty messages
                    nested_type.append(
                        "  // This message intentionally left empty or will be extended later"
                    )
                    nested_type.append("  reserved 1;")

                # Close message definition
                nested_type.append("}")
                nested_type.append("")

            return type_name, is_repeated, nested_type

        # Map primitive JSON Schema types to Protocol Buffer types
        schema_type = schema.get("type")
        schema_format = schema.get("format", "")

        if schema_type == "string":
            if schema_format == "date-time":
                return "google.protobuf.Timestamp", is_repeated, nested_type
            elif schema_format == "date":
                return "google.protobuf.Timestamp", is_repeated, nested_type
            elif schema_format == "time":
                return "string", is_repeated, nested_type
            elif schema_format == "duration":
                return "google.protobuf.Duration", is_repeated, nested_type
            elif schema_format == "byte":
                return "bytes", is_repeated, nested_type
            elif (
                schema_format == "uri"
                or schema_format == "url"
                or schema_format == "email"
            ):
                return "string", is_repeated, nested_type
            else:
                return "string", is_repeated, nested_type

        elif schema_type == "integer":
            if schema_format == "int64" or schema_format == "long":
                return "int64", is_repeated, nested_type
            else:
                return "int32", is_repeated, nested_type

        elif schema_type == "number":
            if schema_format == "float":
                return "float", is_repeated, nested_type
            else:
                return "double", is_repeated, nested_type

        elif schema_type == "boolean":
            return "bool", is_repeated, nested_type

        elif schema_type == "null":
            # Protocol Buffers don't have null, use oneof wrapper later
            return "google.protobuf.StringValue", is_repeated, nested_type

        # Default to string for unknown types
        return "string", is_repeated, nested_type

    @staticmethod
    def _to_snake_case(name: str) -> str:
        """Convert camelCase or PascalCase to snake_case."""
        import re

        s1 = re.sub("(.)([A-Z][a-z]+)", r"\1_\2", name)
        return re.sub("([a-z0-9])([A-Z])", r"\1_\2", s1).lower()

    @staticmethod
    def _sanitize_enum_name(name: str) -> str:
        """Sanitize enum member names for Protocol Buffers."""
        # Replace invalid characters with underscores
        import re

        name = re.sub(r"[^A-Z0-9_]", "_", name)

        # Ensure name doesn't start with a digit
        if name and name[0].isdigit():
            name = f"VALUE_{name}"

        # Prevent duplicate underscores
        while "__" in name:
            name = name.replace("__", "_")

        # Trim leading/trailing underscores
        return name.strip("_")
