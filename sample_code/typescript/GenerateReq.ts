// Code generated by schema2code at 2025-08-26 22:17:57. DO NOT EDIT.


import { ModelParameters } from './ModelParameters';



/**
 * GenerateReq represents a request to the Ollama embeddings API
 */
export interface GenerateReq {
  /**
   * Model name
   */
  model: string;
  /**
   * Prompt to send to the model
   */
  prompt: string;
  /**
   * Suffix to append to the prompt
   */
  suffix?: string;
  /**
   * Images to include with the prompt
   */
  images?: string[];
  /**
   * The format to return a response in. Format can be json or a JSON schema
   */
  format?: Record<string, unknown>;
  /**
   * Additional model parameters listed in the documentation for the Modelfile such as temperature
   */
  options?: ModelParameters;
  /**
   * System message to (overrides what is defined in the Modelfile)
   */
  system?: string;
  /**
   * The prompt template to use (overrides what is defined in the Modelfile)
   */
  template?: string;
  /**
   * If false the response will be returned as a single response object
   */
  stream?: boolean;
  /**
   * If true no formatting will be applied to the prompt
   */
  raw?: boolean;
  /**
   * Controls how long the model will stay loaded into memory
   */
  keep_alive?: number;
  /**
   * the context parameter returned from a previous request
   */
  context?: string;
  /**
   * If true, the model will think before responding, useful for complex queries
   */
  think?: boolean;
}