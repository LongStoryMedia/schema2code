// GENERATED CODE - DO NOT EDIT
// Generated by schema2code proto generator

syntax = "proto3";

package schema;

import "model_parameters.proto";

// GenerateReq represents a request to the Ollama embeddings API
message GenerateReq {
  // Model name
  string model = 1;
  // Prompt to send to the model
  string prompt = 2;
  // Suffix to append to the prompt
  string suffix = 3;
  // Images to include with the prompt
  repeated string images = 4;
  // The format to return a response in. Format can be json or a JSON schema
  message Format {
    // This message intentionally left empty or will be extended later
    reserved 1;
  }
  

  // The format to return a response in. Format can be json or a JSON schema
  Format format = 5;
  // Additional model parameters listed in the documentation for the Modelfile such as temperature
  ModelParameters options = 6;
  // System message to (overrides what is defined in the Modelfile)
  string system = 7;
  // The prompt template to use (overrides what is defined in the Modelfile)
  string template = 8;
  // If false the response will be returned as a single response object
  bool stream = 9;
  // If true no formatting will be applied to the prompt
  bool raw = 10;
  // Controls how long the model will stay loaded into memory
  int32 keep_alive = 11;
  // the context parameter returned from a previous request
  string context = 12;
  // If true, the model will think before responding, useful for complex queries
  bool think = 13;
}
